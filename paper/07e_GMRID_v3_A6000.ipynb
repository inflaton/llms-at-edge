{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab1516a",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42801c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workding dir: d:\\Donghao\\maritime-incidents-ai-agents\n",
      "loading env vars from: d:\\Donghao\\maritime-incidents-ai-agents\\.env.example\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"workding_dir\" not in globals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"workding dir:\", workding_dir)\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "found_dotenv = find_dotenv(\".env\")\n",
    "\n",
    "if len(found_dotenv) == 0:\n",
    "    found_dotenv = find_dotenv(\".env.example\")\n",
    "print(f\"loading env vars from: {found_dotenv}\")\n",
    "load_dotenv(found_dotenv, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81300af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading env vars from: d:\\Donghao\\maritime-incidents-ai-agents\\.env.example\n",
      "Adding d:\\Donghao\\maritime-incidents-ai-agents to sys.path\n",
      "loading d:\\Donghao\\maritime-incidents-ai-agents\\llm_toolkit\\data_utils.py\n",
      "CPU times: total: 1.69 s\n",
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dataset/GMRID_v3.csv',\n",
       " 'paper/data/ollama_model_results_v3-A6000.csv',\n",
       " '8192')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "results_path = \"paper/data/ollama_model_results_v3-A6000.csv\"\n",
    "num_ctx = os.getenv(\"NUM_CTX\")\n",
    "data_path, results_path, num_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f36348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cells above before running anything below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fe9c1",
   "metadata": {},
   "source": [
    "## Evaluating 14 LLMs: 7 Llama3 + 7 Qwen2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df963580",
   "metadata": {},
   "source": [
    "### Evaluating Llama3 LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271e8202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:1b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:34<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3095.00 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:00<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3120.27 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:17<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3137.93 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:52<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3112.00 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:40<00:00,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3100.26 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 17min 47s\n",
      "Wall time: 4h 19min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:1b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce53c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:1b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:30<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3090.15 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 3min 20s\n",
      "Wall time: 51min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:1b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdf286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:58<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 2998.71 seconds\n",
      "category not in json: {}\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:44<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 2984.42 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:38<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 2978.24 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:34<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 2974.21 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:35<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 2975.52 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 17min 36s\n",
      "Wall time: 4h 8min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a866a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:42<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 2982.79 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 4min 26s\n",
      "Wall time: 49min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab94f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.1:8b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:56<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3116.38 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [50:59<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3059.24 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:08<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3068.52 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:12<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3072.75 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:09<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3069.80 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 22min\n",
      "Wall time: 4h 16min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:8b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ff822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading d:\\Donghao\\maritime-incidents-ai-agents\\llm_toolkit\\data_utils.py\n",
      "Evaluating model: llama3.1:8b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:18<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3078.84 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 4min 11s\n",
      "Wall time: 51min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:8b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fff06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2-vision:11b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:58<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3118.05 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [50:57<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3057.64 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:05<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3065.51 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:04<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3064.23 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:05<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3065.24 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 22min 2s\n",
      "Wall time: 4h 16min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:11b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ee7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2-vision:11b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:13<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3073.62 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 4min 31s\n",
      "Wall time: 51min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:11b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38728b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.1:70b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:22:07<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 4927.40 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:27:21<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 5241.76 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:30:55<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 5455.42 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:30:18<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 5418.92 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:29:36<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 5376.40 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 22min 40s\n",
      "Wall time: 7h 20min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:70b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b69c918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.1:70b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:28:26<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 5306.42 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 4min 30s\n",
      "Wall time: 1h 28min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:70b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89007eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.3:70b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:26:46<00:00,  4.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 5206.47 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:21:15<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 4875.65 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:22:38<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 4958.64 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:22:40<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 4960.69 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:22:37<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 4957.27 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 20min 33s\n",
      "Wall time: 6h 56min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.3:70b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcedc54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading env vars from: d:\\Donghao\\maritime-incidents-ai-agents\\.env.example\n",
      "Adding d:\\Donghao\\maritime-incidents-ai-agents to sys.path\n",
      "Evaluating model: llama3.3:70b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:22:08<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 4928.90 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 4min 34s\n",
      "Wall time: 1h 22min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.3:70b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce77907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2-vision:90b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [3:48:01<00:00, 11.93s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 13681.65 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [4:24:11<00:00, 13.82s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 15851.37 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [4:44:41<00:00, 14.89s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 17081.07 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [4:36:25<00:00, 14.46s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 16585.81 seconds\n",
      "'float' object has no attribute 'size'\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and Summarized_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [4:35:54<00:00, 14.43s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 16554.42 seconds\n",
      "'float' object has no attribute 'size'\n",
      "CPU times: total: 19min 27s\n",
      "Wall time: 22h 9min 21s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:90b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42ca867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2-vision:90b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [4:39:03<00:00, 14.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 16743.58 seconds\n",
      "llama3.2-vision:90b/shots-10(14.598) metrics: {'f1': 0.9544707611992286, 'accuracy': 0.9546643417611159}\n",
      "CPU times: total: 3min 25s\n",
      "Wall time: 4h 39min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:90b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0137e290",
   "metadata": {},
   "source": [
    "## Evaluating Qwen2.5 LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f532c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:0.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [48:59<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 2939.73 seconds\n",
      "qwen2.5:0.5b/shots-00(2.563) metrics: {'f1': 0.3956376056576321, 'accuracy': 0.32868352223190933}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [48:53<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 2933.23 seconds\n",
      "qwen2.5:0.5b/shots-01(2.557) metrics: {'f1': 0.4560196093674358, 'accuracy': 0.4237140366172624}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [48:56<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 2936.65 seconds\n",
      "qwen2.5:0.5b/shots-02(2.560) metrics: {'f1': 0.42982944770339115, 'accuracy': 0.43940714908456846}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:00<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 2940.63 seconds\n",
      "qwen2.5:0.5b/shots-04(2.564) metrics: {'f1': 0.40738307398217627, 'accuracy': 0.44812554489973844}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:09<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 2949.05 seconds\n",
      "qwen2.5:0.5b/shots-08(2.571) metrics: {'f1': 0.445344649942727, 'accuracy': 0.4969485614646905}\n",
      "CPU times: total: 17min 7s\n",
      "Wall time: 4h 5min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:0.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430f1e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:0.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:11<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 2951.27 seconds\n",
      "qwen2.5:0.5b/shots-10(2.573) metrics: {'f1': 0.4585243842864188, 'accuracy': 0.4978204010462075}\n",
      "CPU times: total: 3min 34s\n",
      "Wall time: 49min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:0.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd70c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:1.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:16<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 2956.83 seconds\n",
      "qwen2.5:1.5b/shots-00(2.578) metrics: {'f1': 0.5968787516612039, 'accuracy': 0.5292066259808196}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:09<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 2949.37 seconds\n",
      "qwen2.5:1.5b/shots-01(2.571) metrics: {'f1': 0.7437736712573402, 'accuracy': 0.6617262423714037}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:11<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 2951.50 seconds\n",
      "qwen2.5:1.5b/shots-02(2.573) metrics: {'f1': 0.7278194124620956, 'accuracy': 0.6373147340889277}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:10<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 2950.08 seconds\n",
      "qwen2.5:1.5b/shots-04(2.572) metrics: {'f1': 0.6820534476500574, 'accuracy': 0.5945945945945946}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:20<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 2960.22 seconds\n",
      "qwen2.5:1.5b/shots-08(2.581) metrics: {'f1': 0.643338898343418, 'accuracy': 0.5658238884045336}\n",
      "CPU times: total: 17min 31s\n",
      "Wall time: 4h 6min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:1.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d2cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:1.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:24<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 2964.23 seconds\n",
      "qwen2.5:1.5b/shots-10(2.584) metrics: {'f1': 0.6962222926605997, 'accuracy': 0.6198779424585876}\n",
      "CPU times: total: 3min 31s\n",
      "Wall time: 49min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:1.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85f8afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:52<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 2992.47 seconds\n",
      "qwen2.5:3b/shots-00(2.609) metrics: {'f1': 0.749088909187772, 'accuracy': 0.7419354838709677}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:44<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 2984.55 seconds\n",
      "qwen2.5:3b/shots-01(2.602) metrics: {'f1': 0.8844930523232698, 'accuracy': 0.8622493461203139}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:46<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 2986.63 seconds\n",
      "qwen2.5:3b/shots-02(2.604) metrics: {'f1': 0.8828849427391043, 'accuracy': 0.8587619877942458}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:47<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 2987.17 seconds\n",
      "qwen2.5:3b/shots-04(2.604) metrics: {'f1': 0.8918467797829202, 'accuracy': 0.8674803836094158}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:51<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 2991.04 seconds\n",
      "qwen2.5:3b/shots-08(2.608) metrics: {'f1': 0.9099600064839988, 'accuracy': 0.8927637314734089}\n",
      "CPU times: total: 15min 49s\n",
      "Wall time: 4h 9min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dda00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting debug mode to: True\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Task: Classify Inputs into Predefined Categories\\n\\nYour primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\\n\\nGuidelines:\\n1. Understand the Categories:\\nEach category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\\n\\n{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\\n\\n2. Contextual Analysis:\\nConsider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\\n3. Handling Ambiguity:\\nFor ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\\n4. Ensure Accuracy and Consistency:\\nStrive for consistent and accurate classifications. Avoid arbitrary or random assignments.\\n5. Provide Feedback:\\nIf the input cannot be classified into any of the given categories, classify it as “Others.”\\n\\nInstructions for Output:\\n1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\\n2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\\n\\nOutput Format:\\n\\nReturn your classification in the following JSON format:\\n\\n{\\n  \\\"category\\\": \\\"<Selected Category>\\\",\\n  \\\"specific_tags\\\": [\\\"<Selected Tag 1>\\\", \\\"<Selected Tag 2>\\\", ...]\\n}\\n\\n\\n\\nExample Inputs and Outputs:\\n\\n- Input:\\n\\nLocal sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Weather\\\",\\n  \\\"specific_tags\\\": [\\\"Severe Winds\\\"]\\n}\\n\\n- Input:\\n\\nInformation received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Roadway Closure\\\", \\\"Public Safety Advisory\\\"]\\n}\\n\\n- Input:\\n\\nProtests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Worker Strike\\\",\\n  \\\"specific_tags\\\": [\\\"Protest\\\", \\\"Civil Unrest Advisory\\\"]\\n}\\n\\n- Input:\\n\\nGovernment sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Accident\\\",\\n  \\\"specific_tags\\\": [\\\"Non-industrial Fire\\\"]\\n}\\n\\n- Input:\\n\\nLocal media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Cargo Theft\\\", \\\"Organized Crime\\\"]\\n}\\n\\n- Input:\\n\\nAnonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Cyber Attack\\\",\\n  \\\"specific_tags\\\": [\\\"Ransomware\\\", \\\"Data Breach\\\"]\\n}\\n\\n- Input:\\n\\nThe Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Others\\\",\\n  \\\"specific_tags\\\": [\\\"Outbreak of Disease\\\"]\\n}\\n\\n- Input:\\n\\nAn incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Human Error\\\",\\n  \\\"specific_tags\\\": [\\\"Workplace Accident\\\"]\\n}\\n\\n- Input:\\n\\nShipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Customs Delay\\\", \\\"Port Disruption\\\"]\\n}\\n\\n- Input:\\n\\nRussian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\\n\\n\\nHuman: - Input:\\n\\nCourts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\\n\\n- Output:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1147 [00:02<52:38,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [2.50s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"qwen2.5:3b\",\n",
      "          \"created_at\": \"2024-12-22T21:56:54.306669Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 454113400,\n",
      "          \"load_duration\": 11417800,\n",
      "          \"prompt_eval_count\": 2081,\n",
      "          \"prompt_eval_duration\": 121000000,\n",
      "          \"eval_count\": 25,\n",
      "          \"eval_duration\": 312000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"qwen2.5:3b\",\n",
      "              \"created_at\": \"2024-12-22T21:56:54.306669Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 454113400,\n",
      "              \"load_duration\": 11417800,\n",
      "              \"prompt_eval_count\": 2081,\n",
      "              \"prompt_eval_duration\": 121000000,\n",
      "              \"eval_count\": 25,\n",
      "              \"eval_duration\": 312000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-99deb99f-6921-49f8-b781-be07fd4d4d06-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 2081,\n",
      "              \"output_tokens\": 25,\n",
      "              \"total_tokens\": 2106\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.50s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "Setting debug mode to: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [49:53<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 2993.46 seconds\n",
      "qwen2.5:3b/shots-10(2.610) metrics: {'f1': 0.9024281445311965, 'accuracy': 0.8814298169136879}\n",
      "CPU times: total: 2min 45s\n",
      "Wall time: 49min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f19adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Task: Classify Inputs into Predefined Categories\n",
      "\n",
      "Your primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\n",
      "\n",
      "Guidelines:\n",
      "1. Understand the Categories:\n",
      "Each category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\n",
      "\n",
      "{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\n",
      "\n",
      "2. Contextual Analysis:\n",
      "Consider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\n",
      "3. Handling Ambiguity:\n",
      "For ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\n",
      "4. Ensure Accuracy and Consistency:\n",
      "Strive for consistent and accurate classifications. Avoid arbitrary or random assignments.\n",
      "5. Provide Feedback:\n",
      "If the input cannot be classified into any of the given categories, classify it as “Others.”\n",
      "\n",
      "Instructions for Output:\n",
      "1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\n",
      "2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\n",
      "\n",
      "Output Format:\n",
      "\n",
      "Return your classification in the following JSON format:\n",
      "\n",
      "{\n",
      "  \"category\": \"<Selected Category>\",\n",
      "  \"specific_tags\": [\"<Selected Tag 1>\", \"<Selected Tag 2>\", ...]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Example Inputs and Outputs:\n",
      "\n",
      "- Input:\n",
      "\n",
      "Local sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Weather\",\n",
      "  \"specific_tags\": [\"Severe Winds\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Information received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Administrative Issue\",\n",
      "  \"specific_tags\": [\"Roadway Closure\", \"Public Safety Advisory\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Protests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Worker Strike\",\n",
      "  \"specific_tags\": [\"Protest\", \"Civil Unrest Advisory\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Government sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Accident\",\n",
      "  \"specific_tags\": [\"Non-industrial Fire\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Local media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Terrorism\",\n",
      "  \"specific_tags\": [\"Cargo Theft\", \"Organized Crime\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Anonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Cyber Attack\",\n",
      "  \"specific_tags\": [\"Ransomware\", \"Data Breach\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "The Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Others\",\n",
      "  \"specific_tags\": [\"Outbreak of Disease\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "An incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Human Error\",\n",
      "  \"specific_tags\": [\"Workplace Accident\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Shipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Administrative Issue\",\n",
      "  \"specific_tags\": [\"Customs Delay\", \"Port Disruption\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Russian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Terrorism\",\n",
      "  \"specific_tags\": [\"Bomb Threat\", \"Public Safety\"]\n",
      "}\n",
      "\n",
      "\n",
      "Human: - Input:\n",
      "\n",
      "Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\n",
      "\n",
      "- Output:\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"System: Task: Classify Inputs into Predefined Categories\\n\\nYour primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\\n\\nGuidelines:\\n1. Understand the Categories:\\nEach category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\\n\\n{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\\n\\n2. Contextual Analysis:\\nConsider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\\n3. Handling Ambiguity:\\nFor ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\\n4. Ensure Accuracy and Consistency:\\nStrive for consistent and accurate classifications. Avoid arbitrary or random assignments.\\n5. Provide Feedback:\\nIf the input cannot be classified into any of the given categories, classify it as “Others.”\\n\\nInstructions for Output:\\n1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\\n2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\\n\\nOutput Format:\\n\\nReturn your classification in the following JSON format:\\n\\n{\\n  \\\"category\\\": \\\"<Selected Category>\\\",\\n  \\\"specific_tags\\\": [\\\"<Selected Tag 1>\\\", \\\"<Selected Tag 2>\\\", ...]\\n}\\n\\n\\n\\nExample Inputs and Outputs:\\n\\n- Input:\\n\\nLocal sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Weather\\\",\\n  \\\"specific_tags\\\": [\\\"Severe Winds\\\"]\\n}\\n\\n- Input:\\n\\nInformation received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Roadway Closure\\\", \\\"Public Safety Advisory\\\"]\\n}\\n\\n- Input:\\n\\nProtests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Worker Strike\\\",\\n  \\\"specific_tags\\\": [\\\"Protest\\\", \\\"Civil Unrest Advisory\\\"]\\n}\\n\\n- Input:\\n\\nGovernment sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Accident\\\",\\n  \\\"specific_tags\\\": [\\\"Non-industrial Fire\\\"]\\n}\\n\\n- Input:\\n\\nLocal media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Cargo Theft\\\", \\\"Organized Crime\\\"]\\n}\\n\\n- Input:\\n\\nAnonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Cyber Attack\\\",\\n  \\\"specific_tags\\\": [\\\"Ransomware\\\", \\\"Data Breach\\\"]\\n}\\n\\n- Input:\\n\\nThe Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Others\\\",\\n  \\\"specific_tags\\\": [\\\"Outbreak of Disease\\\"]\\n}\\n\\n- Input:\\n\\nAn incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Human Error\\\",\\n  \\\"specific_tags\\\": [\\\"Workplace Accident\\\"]\\n}\\n\\n- Input:\\n\\nShipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Customs Delay\\\", \\\"Port Disruption\\\"]\\n}\\n\\n- Input:\\n\\nRussian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\\n\\n\\nHuman: - Input:\\n\\nCourts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\\n\\n- Output:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdefff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:7b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:20<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3080.79 seconds\n",
      "qwen2.5:7b/shots-00(2.686) metrics: {'f1': 0.9001961130594346, 'accuracy': 0.8962510897994769}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:01<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3061.74 seconds\n",
      "qwen2.5:7b/shots-01(2.669) metrics: {'f1': 0.9180364399352638, 'accuracy': 0.9049694856146469}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:14<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3074.78 seconds\n",
      "qwen2.5:7b/shots-02(2.681) metrics: {'f1': 0.9194088799200296, 'accuracy': 0.9136878814298169}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:23<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3083.37 seconds\n",
      "qwen2.5:7b/shots-04(2.688) metrics: {'f1': 0.9151124343202138, 'accuracy': 0.9084568439407149}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:28<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3088.35 seconds\n",
      "qwen2.5:7b/shots-08(2.693) metrics: {'f1': 0.9161256129178684, 'accuracy': 0.9075850043591979}\n",
      "CPU times: total: 17min 18s\n",
      "Wall time: 4h 16min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:7b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2baa616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading d:\\Donghao\\maritime-incidents-ai-agents\\llm_toolkit\\data_utils.py\n",
      "Evaluating model: qwen2.5:7b\n",
      "loading train/test data files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23a4579a0b74ecca073fac885ba8834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10babdd30d7640c590d7a4a876842acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:15<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3075.23 seconds\n",
      "qwen2.5:7b/shots-10(2.681) metrics: {'f1': 0.9282894178983229, 'accuracy': 0.9224062772449869}\n",
      "CPU times: total: 4min 26s\n",
      "Wall time: 51min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:7b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "677651da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:14b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [54:56<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3296.86 seconds\n",
      "qwen2.5:14b/shots-00(2.874) metrics: {'f1': 0.8848366758489808, 'accuracy': 0.8831734960767219}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [54:31<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3271.64 seconds\n",
      "qwen2.5:14b/shots-01(2.852) metrics: {'f1': 0.9457126893600687, 'accuracy': 0.941586748038361}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [54:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3268.37 seconds\n",
      "qwen2.5:14b/shots-02(2.849) metrics: {'f1': 0.9404628437554393, 'accuracy': 0.937227550130776}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [54:39<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3279.96 seconds\n",
      "qwen2.5:14b/shots-04(2.860) metrics: {'f1': 0.9294905140450944, 'accuracy': 0.9250217959895379}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:05<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3305.69 seconds\n",
      "qwen2.5:14b/shots-08(2.882) metrics: {'f1': 0.9376867879813737, 'accuracy': 0.934612031386225}\n",
      "CPU times: total: 21min 12s\n",
      "Wall time: 4h 33min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:14b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c145398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:14b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:12<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3312.96 seconds\n",
      "qwen2.5:14b/shots-10(2.888) metrics: {'f1': 0.9500250926638638, 'accuracy': 0.946817785527463}\n",
      "CPU times: total: 3min 35s\n",
      "Wall time: 55min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:14b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47302897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:32b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:03:56<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3836.96 seconds\n",
      "qwen2.5:32b/shots-00(3.345) metrics: {'f1': 0.9283242190649389, 'accuracy': 0.9267654751525719}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:01:43<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3703.78 seconds\n",
      "qwen2.5:32b/shots-01(3.229) metrics: {'f1': 0.9575550638190302, 'accuracy': 0.955536181342633}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:03:18<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3798.68 seconds\n",
      "qwen2.5:32b/shots-02(3.312) metrics: {'f1': 0.9571844979649234, 'accuracy': 0.95640802092415}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:53<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3773.16 seconds\n",
      "qwen2.5:32b/shots-04(3.290) metrics: {'f1': 0.9622535355596386, 'accuracy': 0.960767218831735}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:03:21<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3801.76 seconds\n",
      "qwen2.5:32b/shots-08(3.315) metrics: {'f1': 0.9668225511204042, 'accuracy': 0.9659982563208369}\n",
      "CPU times: total: 17min 21s\n",
      "Wall time: 5h 15min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:32b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa153c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:32b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:03:41<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3821.96 seconds\n",
      "qwen2.5:32b/shots-10(3.332) metrics: {'f1': 0.9653028876450642, 'accuracy': 0.963382737576286}\n",
      "CPU times: total: 3min 35s\n",
      "Wall time: 1h 3min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:32b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1203e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:72b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:57:13<00:00,  6.13s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 7033.23 seconds\n",
      "qwen2.5:72b/shots-00(6.132) metrics: {'f1': 0.9315951746873947, 'accuracy': 0.923278116826504}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:50:53<00:00,  5.80s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 6653.38 seconds\n",
      "qwen2.5:72b/shots-01(5.801) metrics: {'f1': 0.9470227387224437, 'accuracy': 0.9380993897122929}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:51:55<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 6715.12 seconds\n",
      "qwen2.5:72b/shots-02(5.855) metrics: {'f1': 0.957558821059243, 'accuracy': 0.9520488230165649}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:52:06<00:00,  5.86s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 6726.85 seconds\n",
      "qwen2.5:72b/shots-04(5.865) metrics: {'f1': 0.9656812070305312, 'accuracy': 0.963382737576286}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:52:59<00:00,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 6779.97 seconds\n",
      "qwen2.5:72b/shots-08(5.911) metrics: {'f1': 0.9707583280385403, 'accuracy': 0.9686137750653879}\n",
      "CPU times: total: 17min 49s\n",
      "Wall time: 9h 25min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:72b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd70038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:72b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:52:30<00:00,  5.89s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 6750.92 seconds\n",
      "qwen2.5:72b/shots-10(5.886) metrics: {'f1': 0.96337172315667, 'accuracy': 0.959895379250218}\n",
      "CPU times: total: 4min 1s\n",
      "Wall time: 1h 52min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:72b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc24fc",
   "metadata": {},
   "source": [
    "## System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3727bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cbce17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 61.63 GB\n",
      "Available memory: 47.01 GB\n",
      "Used memory: 14.61 GB\n",
      "Memory percentage: 23.7%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the system memory information\n",
    "memory_info = psutil.virtual_memory()\n",
    "\n",
    "# Print the total, available, and used memory\n",
    "print(f\"Total memory: {memory_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available memory: {memory_info.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used memory: {memory_info.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Memory percentage: {memory_info.percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ef7ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Windows\n",
      "Node Name: DESKTOP-63OF5PB\n",
      "Release: 10\n",
      "Version: 10.0.22631\n",
      "Machine: AMD64\n",
      "Processor: AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "\n",
    "def get_os_info():\n",
    "    os_info = {\n",
    "        \"System\": platform.system(),\n",
    "        \"Node Name\": platform.node(),\n",
    "        \"Release\": platform.release(),\n",
    "        \"Version\": platform.version(),\n",
    "        \"Machine\": platform.machine(),\n",
    "        \"Processor\": platform.processor(),\n",
    "    }\n",
    "    return os_info\n",
    "\n",
    "\n",
    "os_info = get_os_info()\n",
    "for key, value in os_info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e6d9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date/time: 2024-12-23 19:00:20.343216\n"
     ]
    }
   ],
   "source": [
    "# printe current date & time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print(\"Current date/time:\", now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
