{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1720679526275,
     "user": {
      "displayName": "HUANG DONGHAO _",
      "userId": "00977795705617022768"
     },
     "user_tz": -480
    },
    "id": "uWKRSV6eZsCn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d394937-6c99-4a7c-9d32-7600a280032f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1720679529345,
     "user": {
      "displayName": "HUANG DONGHAO _",
      "userId": "00977795705617022768"
     },
     "user_tz": -480
    },
    "id": "G5pNu3zgZBrL",
    "outputId": "160a554f-fb08-4aa0-bc00-0422fb7c1fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workding dir: /Users/inflaton/code/engd/papers/maritime-incidents-ai-agents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# check if workding_dir is in local variables\n",
    "if \"workding_dir\" not in locals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"workding dir:\", workding_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f67ec60-2f24-411c-84eb-0dd664b44775",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1720679529345,
     "user": {
      "displayName": "HUANG DONGHAO _",
      "userId": "00977795705617022768"
     },
     "user_tz": -480
    },
    "id": "hPCC-6m7ZBrM",
    "outputId": "c7aa2c96-5e99-440a-c148-201d79465ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading env vars from: /Users/inflaton/code/engd/papers/maritime-incidents-ai-agents/.env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "found_dotenv = find_dotenv(\".env\")\n",
    "\n",
    "if len(found_dotenv) == 0:\n",
    "    found_dotenv = find_dotenv(\".env.example\")\n",
    "print(f\"loading env vars from: {found_dotenv}\")\n",
    "load_dotenv(found_dotenv, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1597656-8042-4878-9d3b-9ebfb8dd86dc",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1720679529345,
     "user": {
      "displayName": "HUANG DONGHAO _",
      "userId": "00977795705617022768"
     },
     "user_tz": -480
    },
    "id": "1M3IraVtZBrM",
    "outputId": "29ab35f6-2970-4ade-d85d-3174acf8cda0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 μs, sys: 39 μs, total: 244 μs\n",
      "Wall time: 242 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dataset/GMRID_v3.csv',\n",
       " 'paper/data/ollama_model_results_v3-A6000_top_metrics.csv',\n",
       " '8192')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "results_path = \"paper/data/ollama_model_results_v3-A6000_top_metrics.csv\"\n",
    "num_ctx = os.getenv(\"NUM_CTX\")\n",
    "data_path, results_path, num_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   model                   20 non-null     object \n",
      " 1   shots                   20 non-null     int64  \n",
      " 2   eval_time               20 non-null     float64\n",
      " 3   f1                      20 non-null     float64\n",
      " 4   accuracy                20 non-null     float64\n",
      " 5   f1_raw                  20 non-null     float64\n",
      " 6   accuracy_raw            20 non-null     float64\n",
      " 7   ratio_valid_categories  20 non-null     float64\n",
      " 8   total_tokens            20 non-null     int64  \n",
      " 9   eval_speed              20 non-null     float64\n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llm_toolkit.llm_utils import *\n",
    "from llm_toolkit.data_utils import *\n",
    "\n",
    "df = pd.read_csv(results_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"paper/data/ollama_model_results_v3-RTX4090_top_metrics.csv\")\n",
    "df3 = pd.read_csv(\"paper/data/ollama_model_results_v3-M3_Max_top_metrics.csv\")\n",
    "df4 = pd.read_csv(\"paper/data/ollama_model_results_v3-M4_Max_top_metrics.csv\")\n",
    "df5 = pd.read_csv(\"paper/data/ollama_model_results_v3-RTX4090_Laptop_top_metrics.csv\")\n",
    "df6 = pd.read_csv(\"paper/data/ollama_model_results_v3-Jetson_AGX_Orin_top_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qwen2.5:0.5b': 0.5,\n",
       " 'llama3.2:1b': 1,\n",
       " 'qwen2.5:1.5b': 1.5,\n",
       " 'llama3.2:3b': 3,\n",
       " 'qwen2.5:3b': 4,\n",
       " 'qwen2.5:7b': 12,\n",
       " 'llama3.1:8b': 15,\n",
       " 'llama3.2-vision': 21,\n",
       " 'llama3.2-vision:11b': 21,\n",
       " 'qwen2.5:14b': 22,\n",
       " 'qwen2.5:32b': 23,\n",
       " 'llama3.1:70b': 25,\n",
       " 'llama3.3:70b': 30.1,\n",
       " 'qwen2.5:72b': 30.2,\n",
       " 'llama3.2-vision:90b': 31}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orders = {\n",
    "    k.replace(\"-coder\", \"\").replace(\"-Coder\", \"\"): v\n",
    "    for k, v in model_orders.items()\n",
    "    if \"qwq\" not in k.lower() and \"/\" not in k and \"fp16\" not in k and \"gpt\" not in k\n",
    "}\n",
    "model_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qwen2.5:0.5b',\n",
       " 'llama3.2:1b',\n",
       " 'qwen2.5:1.5b',\n",
       " 'llama3.2:3b',\n",
       " 'qwen2.5:3b',\n",
       " 'qwen2.5:7b',\n",
       " 'llama3.1:8b',\n",
       " 'llama3.2-vision:11b',\n",
       " 'qwen2.5:14b',\n",
       " 'qwen2.5:32b',\n",
       " 'llama3.1:70b',\n",
       " 'llama3.3:70b',\n",
       " 'qwen2.5:72b',\n",
       " 'llama3.2-vision:90b']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = [model for model in df[\"model\"].unique() if model in model_orders]\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_models = all_models[:5]\n",
    "medium_models = all_models[5:10]\n",
    "large_models = all_models[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = df[df[\"model\"].isin(all_models)]\n",
    "metrics_df2 = df2[df2[\"model\"].isin(all_models)]\n",
    "metrics_df3 = df3[df3[\"model\"].isin(all_models)]\n",
    "metrics_df4 = df4[df4[\"model\"].isin(all_models)]\n",
    "metrics_df5 = df5[df5[\"model\"].isin(all_models)]\n",
    "metrics_df6 = df6[df6[\"model\"].isin(all_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_map = {\n",
    "    \"RTX A6000\": metrics_df,\n",
    "    \"RTX 4090\": metrics_df2,\n",
    "    \"M3 Max\": metrics_df3,\n",
    "    \"M4 Max\": metrics_df4,\n",
    "    \"RTX 4090 Laptop\": metrics_df5,\n",
    "    \"Jetson AGX Orin\": metrics_df6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_performance_table(metrics_map, models):\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate over models\n",
    "    for model in models:\n",
    "        f1_scores = []\n",
    "        throughputs = []\n",
    "        eval_times = []\n",
    "\n",
    "        # Collect data across devices\n",
    "        for device, df in metrics_map.items():\n",
    "            # Filter for the specific model\n",
    "            model_data = df[df[\"model\"] == model]\n",
    "            if not model_data.empty:\n",
    "                f1 = model_data[\"f1\"].values[0] * 100\n",
    "                throughput = model_data[\"eval_speed\"].values[0]\n",
    "                eval_time = model_data[\"eval_time\"].values[0]\n",
    "                \n",
    "                # Append row for each device\n",
    "                rows.append({\n",
    "                    \"Model\": model,\n",
    "                    \"Platform/Stats\": device,\n",
    "                    \"F1 (%)\": f1,\n",
    "                    \"T-put (t/s)\": throughput,\n",
    "                    \"Time (s)\": eval_time,\n",
    "                })\n",
    "                f1_scores.append(f1)\n",
    "                throughputs.append(throughput)\n",
    "                eval_times.append(eval_time)\n",
    "            else:\n",
    "                # If no data, append placeholders\n",
    "                rows.append({\n",
    "                    \"Model\": model,\n",
    "                    \"Platform/Stats\": device,\n",
    "                    \"F1 (%)\": \"-\",\n",
    "                    \"T-put (t/s)\": \"-\",\n",
    "                    \"Time (s)\": \"-\",\n",
    "                })\n",
    "        \n",
    "        # Add mean and std rows for the current model\n",
    "        rows.append({\n",
    "            \"Model\": model,\n",
    "            \"Platform/Stats\": \"mean\",\n",
    "            \"F1 (%)\": np.mean(f1_scores) if f1_scores else \"-\",\n",
    "            \"T-put (t/s)\": np.mean(throughputs) if throughputs else \"-\",\n",
    "            \"Time (s)\": np.mean(eval_times) if eval_times else \"-\",\n",
    "        })\n",
    "        rows.append({\n",
    "            \"Model\": model,\n",
    "            \"Platform/Stats\": \"std\",\n",
    "            \"F1 (%)\": np.std(f1_scores) if f1_scores else \"-\",\n",
    "            \"T-put (t/s)\": np.std(throughputs) if throughputs else \"-\",\n",
    "            \"Time (s)\": np.std(eval_times) if eval_times else \"-\",\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    table_df = pd.DataFrame(rows)\n",
    "    table_df.set_index([\"Model\", \"Platform/Stats\"], inplace=True)\n",
    "\n",
    "    table_df[\"F1 (%)\"] = table_df[\"F1 (%)\"].apply(lambda x: f\"{x:.2f}\" if x != \"-\" else x)\n",
    "    table_df[\"T-put (t/s)\"] = table_df[\"T-put (t/s)\"].apply(lambda x: f\"{x:.0f}\" if x != \"-\" else x)\n",
    "    table_df[\"Time (s)\"] = table_df[\"Time (s)\"].apply(lambda x: f\"{x:.3f}\" if x != \"-\" else x)\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_models_perf = generate_performance_table(metrics_map, small_models)\n",
    "medium_models_perf = generate_performance_table(metrics_map, medium_models)\n",
    "large_models_perf = generate_performance_table(metrics_map, large_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Small Models\n",
      "|                                     |   F1 (%) |   T-put (t/s) |   Time (s) |\n",
      "|:------------------------------------|---------:|--------------:|-----------:|\n",
      "| ('qwen2.5:0.5b', 'RTX A6000')       |    45.85 |           816 |      2.573 |\n",
      "| ('qwen2.5:0.5b', 'RTX 4090')        |    48.22 |         13124 |      0.16  |\n",
      "| ('qwen2.5:0.5b', 'M3 Max')          |    47.45 |          7178 |      0.258 |\n",
      "| ('qwen2.5:0.5b', 'M4 Max')          |    46.08 |          9632 |      0.218 |\n",
      "| ('qwen2.5:0.5b', 'RTX 4090 Laptop') |    46.58 |           776 |      2.707 |\n",
      "| ('qwen2.5:0.5b', 'Jetson AGX Orin') |    46.65 |          1762 |      1.192 |\n",
      "| ('qwen2.5:0.5b', 'mean')            |    46.8  |          5548 |      1.185 |\n",
      "| ('qwen2.5:0.5b', 'std')             |     0.81 |          4765 |      1.087 |\n",
      "| ('llama3.2:1b', 'RTX A6000')        |    63.14 |           401 |      2.698 |\n",
      "| ('llama3.2:1b', 'RTX 4090')         |    63.51 |          5035 |      0.215 |\n",
      "| ('llama3.2:1b', 'M3 Max')           |    63.5  |          1899 |      0.57  |\n",
      "| ('llama3.2:1b', 'M4 Max')           |    63.34 |          2400 |      0.451 |\n",
      "| ('llama3.2:1b', 'RTX 4090 Laptop')  |    62.65 |           361 |      2.998 |\n",
      "| ('llama3.2:1b', 'Jetson AGX Orin')  |    63.41 |           352 |      3.074 |\n",
      "| ('llama3.2:1b', 'mean')             |    63.26 |          1741 |      1.668 |\n",
      "| ('llama3.2:1b', 'std')              |     0.3  |          1680 |      1.265 |\n",
      "| ('qwen2.5:1.5b', 'RTX A6000')       |    74.38 |           456 |      2.571 |\n",
      "| ('qwen2.5:1.5b', 'RTX 4090')        |    73.66 |          7419 |      0.158 |\n",
      "| ('qwen2.5:1.5b', 'M3 Max')          |    75.13 |          2224 |      0.527 |\n",
      "| ('qwen2.5:1.5b', 'M4 Max')          |    74.09 |          4055 |      0.289 |\n",
      "| ('qwen2.5:1.5b', 'RTX 4090 Laptop') |    74.94 |           429 |      2.733 |\n",
      "| ('qwen2.5:1.5b', 'Jetson AGX Orin') |    72.16 |           740 |      1.583 |\n",
      "| ('qwen2.5:1.5b', 'mean')            |    74.06 |          2554 |      1.31  |\n",
      "| ('qwen2.5:1.5b', 'std')             |     0.98 |          2524 |      1.055 |\n",
      "| ('llama3.2:3b', 'RTX A6000')        |    83.87 |           803 |      2.601 |\n",
      "| ('llama3.2:3b', 'RTX 4090')         |    83.61 |          9766 |      0.214 |\n",
      "| ('llama3.2:3b', 'M3 Max')           |    83.4  |          2521 |      0.829 |\n",
      "| ('llama3.2:3b', 'M4 Max')           |    84.33 |          3779 |      0.553 |\n",
      "| ('llama3.2:3b', 'RTX 4090 Laptop')  |    84.18 |           662 |      2.783 |\n",
      "| ('llama3.2:3b', 'Jetson AGX Orin')  |    84.34 |           596 |      3.091 |\n",
      "| ('llama3.2:3b', 'mean')             |    83.95 |          3021 |      1.679 |\n",
      "| ('llama3.2:3b', 'std')              |     0.36 |          3232 |      1.169 |\n",
      "| ('qwen2.5:3b', 'RTX A6000')         |    91    |           710 |      2.608 |\n",
      "| ('qwen2.5:3b', 'RTX 4090')          |    91.3  |          8653 |      0.214 |\n",
      "| ('qwen2.5:3b', 'M3 Max')            |    91.07 |          1197 |      1.547 |\n",
      "| ('qwen2.5:3b', 'M4 Max')            |    91.03 |          3802 |      0.487 |\n",
      "| ('qwen2.5:3b', 'RTX 4090 Laptop')   |    90.65 |           659 |      2.808 |\n",
      "| ('qwen2.5:3b', 'Jetson AGX Orin')   |    90.46 |           730 |      2.536 |\n",
      "| ('qwen2.5:3b', 'mean')              |    90.92 |          2625 |      1.7   |\n",
      "| ('qwen2.5:3b', 'std')               |     0.28 |          2912 |      1.037 |\n",
      "\n",
      "\n",
      "## Medium Models\n",
      "|                                            |   F1 (%) |   T-put (t/s) |   Time (s) |\n",
      "|:-------------------------------------------|---------:|--------------:|-----------:|\n",
      "| ('qwen2.5:7b', 'RTX A6000')                |    92.83 |           784 |      2.681 |\n",
      "| ('qwen2.5:7b', 'RTX 4090')                 |    92.65 |          6607 |      0.318 |\n",
      "| ('qwen2.5:7b', 'M3 Max')                   |    92.5  |          1194 |      1.76  |\n",
      "| ('qwen2.5:7b', 'M4 Max')                   |    92.72 |          2041 |      1.03  |\n",
      "| ('qwen2.5:7b', 'RTX 4090 Laptop')          |    92.46 |           705 |      2.983 |\n",
      "| ('qwen2.5:7b', 'Jetson AGX Orin')          |    92.78 |           410 |      5.13  |\n",
      "| ('qwen2.5:7b', 'mean')                     |    92.66 |          1957 |      2.317 |\n",
      "| ('qwen2.5:7b', 'std')                      |     0.14 |          2143 |      1.552 |\n",
      "| ('llama3.1:8b', 'RTX A6000')               |    93.1  |           778 |      2.684 |\n",
      "| ('llama3.1:8b', 'RTX 4090')                |    91.96 |          6761 |      0.309 |\n",
      "| ('llama3.1:8b', 'M3 Max')                  |    92.21 |          1430 |      1.461 |\n",
      "| ('llama3.1:8b', 'M4 Max')                  |    93.1  |          2269 |      0.921 |\n",
      "| ('llama3.1:8b', 'RTX 4090 Laptop')         |    93.19 |           706 |      2.959 |\n",
      "| ('llama3.1:8b', 'Jetson AGX Orin')         |    93.1  |           406 |      5.146 |\n",
      "| ('llama3.1:8b', 'mean')                    |    92.78 |          2058 |      2.247 |\n",
      "| ('llama3.1:8b', 'std')                     |     0.5  |          2189 |      1.593 |\n",
      "| ('llama3.2-vision:11b', 'RTX A6000')       |    92.63 |           780 |      2.68  |\n",
      "| ('llama3.2-vision:11b', 'RTX 4090')        |    92.53 |          6293 |      0.332 |\n",
      "| ('llama3.2-vision:11b', 'M3 Max')          |    93.12 |          1232 |      1.696 |\n",
      "| ('llama3.2-vision:11b', 'M4 Max')          |    92.64 |          2261 |      0.924 |\n",
      "| ('llama3.2-vision:11b', 'RTX 4090 Laptop') |    93.39 |           707 |      2.956 |\n",
      "| ('llama3.2-vision:11b', 'Jetson AGX Orin') |    92.82 |           456 |      4.585 |\n",
      "| ('llama3.2-vision:11b', 'mean')            |    92.86 |          1955 |      2.196 |\n",
      "| ('llama3.2-vision:11b', 'std')             |     0.31 |          2026 |      1.406 |\n",
      "| ('qwen2.5:14b', 'RTX A6000')               |    95    |           728 |      2.888 |\n",
      "| ('qwen2.5:14b', 'RTX 4090')                |    94.88 |          3995 |      0.526 |\n",
      "| ('qwen2.5:14b', 'M3 Max')                  |    94.71 |            41 |     28.912 |\n",
      "| ('qwen2.5:14b', 'M4 Max')                  |    94.84 |          1033 |      2.035 |\n",
      "| ('qwen2.5:14b', 'RTX 4090 Laptop')         |    95.09 |           638 |      3.292 |\n",
      "| ('qwen2.5:14b', 'Jetson AGX Orin')         |    95.06 |           204 |     10.304 |\n",
      "| ('qwen2.5:14b', 'mean')                    |    94.93 |          1106 |      7.993 |\n",
      "| ('qwen2.5:14b', 'std')                     |     0.13 |          1333 |      9.852 |\n",
      "| ('qwen2.5:32b', 'RTX A6000')               |    96.68 |           560 |      3.315 |\n",
      "| ('qwen2.5:32b', 'RTX 4090')                |    96.86 |          2128 |      0.872 |\n",
      "| ('qwen2.5:32b', 'M3 Max')                  |    96.95 |           259 |      8.131 |\n",
      "| ('qwen2.5:32b', 'M4 Max')                  |    96.86 |           143 |     12.995 |\n",
      "| ('qwen2.5:32b', 'RTX 4090 Laptop')         |    96.6  |           228 |      8.13  |\n",
      "| ('qwen2.5:32b', 'Jetson AGX Orin')         |    96.68 |            95 |     19.497 |\n",
      "| ('qwen2.5:32b', 'mean')                    |    96.77 |           569 |      8.823 |\n",
      "| ('qwen2.5:32b', 'std')                     |     0.12 |           713 |      6.135 |\n",
      "\n",
      "\n",
      "## Large Models\n",
      "|                                            | F1 (%)   | T-put (t/s)   | Time (s)   |\n",
      "|:-------------------------------------------|:---------|:--------------|:-----------|\n",
      "| ('llama3.1:70b', 'RTX A6000')              | 95.96    | 312           | 4.724      |\n",
      "| ('llama3.1:70b', 'RTX 4090')               | 95.46    | 94            | 15.657     |\n",
      "| ('llama3.1:70b', 'M3 Max')                 | 95.55    | 120           | 12.293     |\n",
      "| ('llama3.1:70b', 'M4 Max')                 | -        | -             | -          |\n",
      "| ('llama3.1:70b', 'RTX 4090 Laptop')        | -        | -             | -          |\n",
      "| ('llama3.1:70b', 'Jetson AGX Orin')        | -        | -             | -          |\n",
      "| ('llama3.1:70b', 'mean')                   | 95.66    | 175           | 10.891     |\n",
      "| ('llama3.1:70b', 'std')                    | 0.22     | 97            | 4.572      |\n",
      "| ('llama3.3:70b', 'RTX A6000')              | 95.87    | 426           | 4.322      |\n",
      "| ('llama3.3:70b', 'RTX 4090')               | 95.73    | 73            | 20.241     |\n",
      "| ('llama3.3:70b', 'M3 Max')                 | 95.90    | 37            | 39.523     |\n",
      "| ('llama3.3:70b', 'M4 Max')                 | -        | -             | -          |\n",
      "| ('llama3.3:70b', 'RTX 4090 Laptop')        | -        | -             | -          |\n",
      "| ('llama3.3:70b', 'Jetson AGX Orin')        | -        | -             | -          |\n",
      "| ('llama3.3:70b', 'mean')                   | 95.83    | 179           | 21.362     |\n",
      "| ('llama3.3:70b', 'std')                    | 0.07     | 176           | 14.393     |\n",
      "| ('qwen2.5:72b', 'RTX A6000')               | 97.08    | 314           | 5.911      |\n",
      "| ('qwen2.5:72b', 'RTX 4090')                | 96.85    | 109           | 17.072     |\n",
      "| ('qwen2.5:72b', 'M3 Max')                  | 96.59    | 116           | 16.055     |\n",
      "| ('qwen2.5:72b', 'M4 Max')                  | -        | -             | -          |\n",
      "| ('qwen2.5:72b', 'RTX 4090 Laptop')         | -        | -             | -          |\n",
      "| ('qwen2.5:72b', 'Jetson AGX Orin')         | -        | -             | -          |\n",
      "| ('qwen2.5:72b', 'mean')                    | 96.84    | 179           | 13.013     |\n",
      "| ('qwen2.5:72b', 'std')                     | 0.20     | 95            | 5.039      |\n",
      "| ('llama3.2-vision:90b', 'RTX A6000')       | 96.05    | 102           | 14.460     |\n",
      "| ('llama3.2-vision:90b', 'RTX 4090')        | 96.13    | 56            | 26.505     |\n",
      "| ('llama3.2-vision:90b', 'M3 Max')          | 95.93    | 85            | 17.379     |\n",
      "| ('llama3.2-vision:90b', 'M4 Max')          | -        | -             | -          |\n",
      "| ('llama3.2-vision:90b', 'RTX 4090 Laptop') | -        | -             | -          |\n",
      "| ('llama3.2-vision:90b', 'Jetson AGX Orin') | -        | -             | -          |\n",
      "| ('llama3.2-vision:90b', 'mean')            | 96.04    | 81            | 19.448     |\n",
      "| ('llama3.2-vision:90b', 'std')             | 0.08     | 19            | 5.130      |\n"
     ]
    }
   ],
   "source": [
    "# Display the performance tables in markdown format\n",
    "print(\"## Small Models\")\n",
    "print(small_models_perf.to_markdown(index=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"## Medium Models\")\n",
    "print(medium_models_perf.to_markdown(index=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"## Large Models\")\n",
    "print(large_models_perf.to_markdown(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " &  & F1 (%) & T-put (t/s) & Time (s) \\\\\n",
      "Model & Platform/Stats &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{8}{*}{qwen2.5:0.5b} & RTX A6000 & 45.85 & 816 & 2.573 \\\\\n",
      " & RTX 4090 & 48.22 & 13124 & 0.160 \\\\\n",
      " & M3 Max & 47.45 & 7178 & 0.258 \\\\\n",
      " & M4 Max & 46.08 & 9632 & 0.218 \\\\\n",
      " & RTX 4090 Laptop & 46.58 & 776 & 2.707 \\\\\n",
      " & Jetson AGX Orin & 46.65 & 1762 & 1.192 \\\\\n",
      " & mean & 46.80 & 5548 & 1.185 \\\\\n",
      " & std & 0.81 & 4765 & 1.087 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.2:1b} & RTX A6000 & 63.14 & 401 & 2.698 \\\\\n",
      " & RTX 4090 & 63.51 & 5035 & 0.215 \\\\\n",
      " & M3 Max & 63.50 & 1899 & 0.570 \\\\\n",
      " & M4 Max & 63.34 & 2400 & 0.451 \\\\\n",
      " & RTX 4090 Laptop & 62.65 & 361 & 2.998 \\\\\n",
      " & Jetson AGX Orin & 63.41 & 352 & 3.074 \\\\\n",
      " & mean & 63.26 & 1741 & 1.668 \\\\\n",
      " & std & 0.30 & 1680 & 1.265 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{qwen2.5:1.5b} & RTX A6000 & 74.38 & 456 & 2.571 \\\\\n",
      " & RTX 4090 & 73.66 & 7419 & 0.158 \\\\\n",
      " & M3 Max & 75.13 & 2224 & 0.527 \\\\\n",
      " & M4 Max & 74.09 & 4055 & 0.289 \\\\\n",
      " & RTX 4090 Laptop & 74.94 & 429 & 2.733 \\\\\n",
      " & Jetson AGX Orin & 72.16 & 740 & 1.583 \\\\\n",
      " & mean & 74.06 & 2554 & 1.310 \\\\\n",
      " & std & 0.98 & 2524 & 1.055 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.2:3b} & RTX A6000 & 83.87 & 803 & 2.601 \\\\\n",
      " & RTX 4090 & 83.61 & 9766 & 0.214 \\\\\n",
      " & M3 Max & 83.40 & 2521 & 0.829 \\\\\n",
      " & M4 Max & 84.33 & 3779 & 0.553 \\\\\n",
      " & RTX 4090 Laptop & 84.18 & 662 & 2.783 \\\\\n",
      " & Jetson AGX Orin & 84.34 & 596 & 3.091 \\\\\n",
      " & mean & 83.95 & 3021 & 1.679 \\\\\n",
      " & std & 0.36 & 3232 & 1.169 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{qwen2.5:3b} & RTX A6000 & 91.00 & 710 & 2.608 \\\\\n",
      " & RTX 4090 & 91.30 & 8653 & 0.214 \\\\\n",
      " & M3 Max & 91.07 & 1197 & 1.547 \\\\\n",
      " & M4 Max & 91.03 & 3802 & 0.487 \\\\\n",
      " & RTX 4090 Laptop & 90.65 & 659 & 2.808 \\\\\n",
      " & Jetson AGX Orin & 90.46 & 730 & 2.536 \\\\\n",
      " & mean & 90.92 & 2625 & 1.700 \\\\\n",
      " & std & 0.28 & 2912 & 1.037 \\\\\n",
      "\\cline{1-5}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(small_models_perf.to_latex(index=True, multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " &  & F1 (%) & T-put (t/s) & Time (s) \\\\\n",
      "Model & Platform/Stats &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{8}{*}{qwen2.5:7b} & RTX A6000 & 92.83 & 784 & 2.681 \\\\\n",
      " & RTX 4090 & 92.65 & 6607 & 0.318 \\\\\n",
      " & M3 Max & 92.50 & 1194 & 1.760 \\\\\n",
      " & M4 Max & 92.72 & 2041 & 1.030 \\\\\n",
      " & RTX 4090 Laptop & 92.46 & 705 & 2.983 \\\\\n",
      " & Jetson AGX Orin & 92.78 & 410 & 5.130 \\\\\n",
      " & mean & 92.66 & 1957 & 2.317 \\\\\n",
      " & std & 0.14 & 2143 & 1.552 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.1:8b} & RTX A6000 & 93.10 & 778 & 2.684 \\\\\n",
      " & RTX 4090 & 91.96 & 6761 & 0.309 \\\\\n",
      " & M3 Max & 92.21 & 1430 & 1.461 \\\\\n",
      " & M4 Max & 93.10 & 2269 & 0.921 \\\\\n",
      " & RTX 4090 Laptop & 93.19 & 706 & 2.959 \\\\\n",
      " & Jetson AGX Orin & 93.10 & 406 & 5.146 \\\\\n",
      " & mean & 92.78 & 2058 & 2.247 \\\\\n",
      " & std & 0.50 & 2189 & 1.593 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.2-vision:11b} & RTX A6000 & 92.63 & 780 & 2.680 \\\\\n",
      " & RTX 4090 & 92.53 & 6293 & 0.332 \\\\\n",
      " & M3 Max & 93.12 & 1232 & 1.696 \\\\\n",
      " & M4 Max & 92.64 & 2261 & 0.924 \\\\\n",
      " & RTX 4090 Laptop & 93.39 & 707 & 2.956 \\\\\n",
      " & Jetson AGX Orin & 92.82 & 456 & 4.585 \\\\\n",
      " & mean & 92.86 & 1955 & 2.196 \\\\\n",
      " & std & 0.31 & 2026 & 1.406 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{qwen2.5:14b} & RTX A6000 & 95.00 & 728 & 2.888 \\\\\n",
      " & RTX 4090 & 94.88 & 3995 & 0.526 \\\\\n",
      " & M3 Max & 94.71 & 41 & 28.912 \\\\\n",
      " & M4 Max & 94.84 & 1033 & 2.035 \\\\\n",
      " & RTX 4090 Laptop & 95.09 & 638 & 3.292 \\\\\n",
      " & Jetson AGX Orin & 95.06 & 204 & 10.304 \\\\\n",
      " & mean & 94.93 & 1106 & 7.993 \\\\\n",
      " & std & 0.13 & 1333 & 9.852 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{qwen2.5:32b} & RTX A6000 & 96.68 & 560 & 3.315 \\\\\n",
      " & RTX 4090 & 96.86 & 2128 & 0.872 \\\\\n",
      " & M3 Max & 96.95 & 259 & 8.131 \\\\\n",
      " & M4 Max & 96.86 & 143 & 12.995 \\\\\n",
      " & RTX 4090 Laptop & 96.60 & 228 & 8.130 \\\\\n",
      " & Jetson AGX Orin & 96.68 & 95 & 19.497 \\\\\n",
      " & mean & 96.77 & 569 & 8.823 \\\\\n",
      " & std & 0.12 & 713 & 6.135 \\\\\n",
      "\\cline{1-5}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(medium_models_perf.to_latex(index=True, multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " &  & F1 (%) & T-put (t/s) & Time (s) \\\\\n",
      "Model & Platform/Stats &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{8}{*}{llama3.1:70b} & RTX A6000 & 95.96 & 312 & 4.724 \\\\\n",
      " & RTX 4090 & 95.46 & 94 & 15.657 \\\\\n",
      " & M3 Max & 95.55 & 120 & 12.293 \\\\\n",
      " & M4 Max & - & - & - \\\\\n",
      " & RTX 4090 Laptop & - & - & - \\\\\n",
      " & Jetson AGX Orin & - & - & - \\\\\n",
      " & mean & 95.66 & 175 & 10.891 \\\\\n",
      " & std & 0.22 & 97 & 4.572 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.3:70b} & RTX A6000 & 95.87 & 426 & 4.322 \\\\\n",
      " & RTX 4090 & 95.73 & 73 & 20.241 \\\\\n",
      " & M3 Max & 95.90 & 37 & 39.523 \\\\\n",
      " & M4 Max & - & - & - \\\\\n",
      " & RTX 4090 Laptop & - & - & - \\\\\n",
      " & Jetson AGX Orin & - & - & - \\\\\n",
      " & mean & 95.83 & 179 & 21.362 \\\\\n",
      " & std & 0.07 & 176 & 14.393 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{qwen2.5:72b} & RTX A6000 & 97.08 & 314 & 5.911 \\\\\n",
      " & RTX 4090 & 96.85 & 109 & 17.072 \\\\\n",
      " & M3 Max & 96.59 & 116 & 16.055 \\\\\n",
      " & M4 Max & - & - & - \\\\\n",
      " & RTX 4090 Laptop & - & - & - \\\\\n",
      " & Jetson AGX Orin & - & - & - \\\\\n",
      " & mean & 96.84 & 179 & 13.013 \\\\\n",
      " & std & 0.20 & 95 & 5.039 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{8}{*}{llama3.2-vision:90b} & RTX A6000 & 96.05 & 102 & 14.460 \\\\\n",
      " & RTX 4090 & 96.13 & 56 & 26.505 \\\\\n",
      " & M3 Max & 95.93 & 85 & 17.379 \\\\\n",
      " & M4 Max & - & - & - \\\\\n",
      " & RTX 4090 Laptop & - & - & - \\\\\n",
      " & Jetson AGX Orin & - & - & - \\\\\n",
      " & mean & 96.04 & 81 & 19.448 \\\\\n",
      " & std & 0.08 & 19 & 5.130 \\\\\n",
      "\\cline{1-5}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(large_models_perf.to_latex(index=True, multirow=True))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "10_eval-lf-medium-py3.11",
   "widgets": {}
  },
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "maritime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
