{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab1516a",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42801c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workding dir: c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\n",
      "loading env vars from: c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\\.env.example\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"workding_dir\" not in globals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"workding dir:\", workding_dir)\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "found_dotenv = find_dotenv(\".env\")\n",
    "\n",
    "if len(found_dotenv) == 0:\n",
    "    found_dotenv = find_dotenv(\".env.example\")\n",
    "print(f\"loading env vars from: {found_dotenv}\")\n",
    "load_dotenv(found_dotenv, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81300af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading env vars from: c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\\.env.example\n",
      "Adding c:\\Users\\dongh\\code\\maritime-incidents-ai-agents to sys.path\n",
      "loading c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\\llm_toolkit\\data_utils.py\n",
      "CPU times: total: 4.44 s\n",
      "Wall time: 49.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dataset/GMRID_v3.csv',\n",
       " 'paper/data/ollama_model_results_v3-RTX4090_Laptop.csv',\n",
       " '8192')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "results_path = \"paper/data/ollama_model_results_v3-RTX4090_Laptop.csv\"\n",
    "num_ctx = os.getenv(\"NUM_CTX\")\n",
    "data_path, results_path, num_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f36348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cells above before running anything below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fe9c1",
   "metadata": {},
   "source": [
    "## Evaluating 14 LLMs: 7 Llama3 + 7 Qwen2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df963580",
   "metadata": {},
   "source": [
    "### Evaluating Llama3 LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271e8202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:1b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [57:18<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3438.30 seconds\n",
      "llama3.2:1b/shots-00(2.998) metrics: {'f1': 0.6265311156444756, 'accuracy': 0.5762859633827376}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3395.56 seconds\n",
      "llama3.2:1b/shots-01(2.960) metrics: {'f1': 0.6045925870843426, 'accuracy': 0.6068003487358327}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:20<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3380.81 seconds\n",
      "llama3.2:1b/shots-02(2.948) metrics: {'f1': 0.6235618433832073, 'accuracy': 0.6041848299912816}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:35<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3335.48 seconds\n",
      "llama3.2:1b/shots-04(2.908) metrics: {'f1': 0.5898555590995646, 'accuracy': 0.5736704446381866}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:36<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3336.71 seconds\n",
      "llama3.2:1b/shots-08(2.909) metrics: {'f1': 0.5102357966195435, 'accuracy': 0.5300784655623365}\n",
      "CPU times: total: 29min 7s\n",
      "Wall time: 4h 41min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:1b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce53c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:1b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [54:39<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3279.30 seconds\n",
      "llama3.2:1b/shots-10(2.859) metrics: {'f1': 0.5698387452004217, 'accuracy': 0.5911072362685266}\n",
      "CPU times: total: 5min 17s\n",
      "Wall time: 54min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:1b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdf286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:38<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3218.70 seconds\n",
      "category not in json: {}\n",
      "llama3.2:3b/shots-00(2.806) metrics: {'f1': 0.6683499213137588, 'accuracy': 0.6748038360941587}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:06<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3186.39 seconds\n",
      "llama3.2:3b/shots-01(2.778) metrics: {'f1': 0.7750838042262678, 'accuracy': 0.7646033129904097}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:48<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3168.86 seconds\n",
      "llama3.2:3b/shots-02(2.763) metrics: {'f1': 0.7975541455583885, 'accuracy': 0.7829119442022667}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:54<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3174.31 seconds\n",
      "llama3.2:3b/shots-04(2.767) metrics: {'f1': 0.7982254960465284, 'accuracy': 0.7863993025283348}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:12<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3192.23 seconds\n",
      "llama3.2:3b/shots-08(2.783) metrics: {'f1': 0.8418426387301592, 'accuracy': 0.8360941586748039}\n",
      "CPU times: total: 25min 49s\n",
      "Wall time: 4h 25min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a866a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:12<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3192.26 seconds\n",
      "llama3.2:3b/shots-10(2.783) metrics: {'f1': 0.8411987554795468, 'accuracy': 0.8352223190932868}\n",
      "CPU times: total: 5min 6s\n",
      "Wall time: 53min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab94f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.1:8b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [57:47<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3467.79 seconds\n",
      "llama3.1:8b/shots-00(3.023) metrics: {'f1': 0.7413537514657786, 'accuracy': 0.7532693984306887}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:01<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3361.85 seconds\n",
      "llama3.1:8b/shots-01(2.931) metrics: {'f1': 0.9071846743925362, 'accuracy': 0.9040976460331299}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:24<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3384.19 seconds\n",
      "llama3.1:8b/shots-02(2.950) metrics: {'f1': 0.8846886665424474, 'accuracy': 0.8840453356582388}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:22<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3382.32 seconds\n",
      "llama3.1:8b/shots-04(2.949) metrics: {'f1': 0.922124786098829, 'accuracy': 0.9206625980819529}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:03<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3363.69 seconds\n",
      "llama3.1:8b/shots-08(2.933) metrics: {'f1': 0.9207095788504032, 'accuracy': 0.9197907585004359}\n",
      "CPU times: total: 25min 44s\n",
      "Wall time: 4h 42min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:8b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ff822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.1:8b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:33<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3393.81 seconds\n",
      "llama3.1:8b/shots-10(2.959) metrics: {'f1': 0.9318785991771351, 'accuracy': 0.9319965126416739}\n",
      "CPU times: total: 5min 9s\n",
      "Wall time: 56min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.1:8b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fff06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: llama3.2-vision:11b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [57:36<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3456.50 seconds\n",
      "llama3.2-vision:11b/shots-00(3.014) metrics: {'f1': 0.7331014265497573, 'accuracy': 0.7471665213600698}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:58<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3358.51 seconds\n",
      "llama3.2-vision:11b/shots-01(2.928) metrics: {'f1': 0.8930347214075045, 'accuracy': 0.8901482127288579}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:13<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3373.20 seconds\n",
      "llama3.2-vision:11b/shots-02(2.941) metrics: {'f1': 0.8755665612801495, 'accuracy': 0.8753269398430689}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:22<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3382.07 seconds\n",
      "llama3.2-vision:11b/shots-04(2.949) metrics: {'f1': 0.9167575884626649, 'accuracy': 0.9154315605928509}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:18<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3378.96 seconds\n",
      "llama3.2-vision:11b/shots-08(2.946) metrics: {'f1': 0.917607339500892, 'accuracy': 0.916303400174368}\n",
      "CPU times: total: 25min 43s\n",
      "Wall time: 4h 42min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:11b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ee7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\\llm_toolkit\\data_utils.py\n",
      "loading env vars from: c:\\Users\\dongh\\code\\maritime-incidents-ai-agents\\.env.example\n",
      "Adding c:\\Users\\dongh\\code\\maritime-incidents-ai-agents to sys.path\n",
      "Evaluating model: llama3.2-vision:11b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:30<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3390.32 seconds\n",
      "llama3.2-vision:11b/shots-10(2.956) metrics: {'f1': 0.9339141589266586, 'accuracy': 0.9337401918047079}\n",
      "CPU times: total: 5min 7s\n",
      "Wall time: 56min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"llama3.2-vision:11b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0137e290",
   "metadata": {},
   "source": [
    "## Evaluating Qwen2.5 LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f532c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:0.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:46<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3106.84 seconds\n",
      "qwen2.5:0.5b/shots-00(2.709) metrics: {'f1': 0.3908628213418354, 'accuracy': 0.3295553618134263}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:40<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3100.84 seconds\n",
      "qwen2.5:0.5b/shots-01(2.703) metrics: {'f1': 0.45756543830334767, 'accuracy': 0.4219703574542284}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:45<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3105.36 seconds\n",
      "qwen2.5:0.5b/shots-02(2.707) metrics: {'f1': 0.4351371505392214, 'accuracy': 0.43940714908456846}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:44<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3104.49 seconds\n",
      "qwen2.5:0.5b/shots-04(2.707) metrics: {'f1': 0.4192220732218152, 'accuracy': 0.4559721011333915}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:49<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3109.27 seconds\n",
      "qwen2.5:0.5b/shots-08(2.711) metrics: {'f1': 0.4429669757470013, 'accuracy': 0.4969485614646905}\n",
      "CPU times: total: 25min 29s\n",
      "Wall time: 4h 18min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:0.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430f1e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:0.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [51:44<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3104.99 seconds\n",
      "qwen2.5:0.5b/shots-10(2.707) metrics: {'f1': 0.46577724044438984, 'accuracy': 0.5039232781168265}\n",
      "CPU times: total: 5min 11s\n",
      "Wall time: 51min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:0.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd70c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:1.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:06<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3126.09 seconds\n",
      "qwen2.5:1.5b/shots-00(2.725) metrics: {'f1': 0.6022011578807978, 'accuracy': 0.5361813426329556}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:14<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3134.81 seconds\n",
      "qwen2.5:1.5b/shots-01(2.733) metrics: {'f1': 0.7493525974822726, 'accuracy': 0.6739319965126417}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:17<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3137.07 seconds\n",
      "qwen2.5:1.5b/shots-02(2.735) metrics: {'f1': 0.726083329934344, 'accuracy': 0.6373147340889277}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:19<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3139.79 seconds\n",
      "qwen2.5:1.5b/shots-04(2.737) metrics: {'f1': 0.682741477962875, 'accuracy': 0.5937227550130776}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:37<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3157.98 seconds\n",
      "qwen2.5:1.5b/shots-08(2.753) metrics: {'f1': 0.6431802986588103, 'accuracy': 0.5675675675675675}\n",
      "CPU times: total: 25min 39s\n",
      "Wall time: 4h 21min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:1.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22d2cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:1.5b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [52:49<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3170.00 seconds\n",
      "qwen2.5:1.5b/shots-10(2.764) metrics: {'f1': 0.7013117945845624, 'accuracy': 0.6277244986922407}\n",
      "CPU times: total: 5min 6s\n",
      "Wall time: 52min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:1.5b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d85f8afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:42<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3222.18 seconds\n",
      "qwen2.5:3b/shots-00(2.809) metrics: {'f1': 0.7587027665001053, 'accuracy': 0.7471665213600698}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:25<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3205.29 seconds\n",
      "qwen2.5:3b/shots-01(2.795) metrics: {'f1': 0.8892586372832157, 'accuracy': 0.8683522231909329}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:29<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3209.42 seconds\n",
      "qwen2.5:3b/shots-02(2.798) metrics: {'f1': 0.8885231276717035, 'accuracy': 0.8639930252833479}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:31<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3211.31 seconds\n",
      "qwen2.5:3b/shots-04(2.800) metrics: {'f1': 0.8953186795103645, 'accuracy': 0.8700959023539668}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:40<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3220.24 seconds\n",
      "qwen2.5:3b/shots-08(2.808) metrics: {'f1': 0.9064736752509356, 'accuracy': 0.8849171752397559}\n",
      "CPU times: total: 25min 38s\n",
      "Wall time: 4h 27min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dda00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:3b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting debug mode to: True\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Task: Classify Inputs into Predefined Categories\\n\\nYour primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\\n\\nGuidelines:\\n1. Understand the Categories:\\nEach category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\\n\\n{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\\n\\n2. Contextual Analysis:\\nConsider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\\n3. Handling Ambiguity:\\nFor ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\\n4. Ensure Accuracy and Consistency:\\nStrive for consistent and accurate classifications. Avoid arbitrary or random assignments.\\n5. Provide Feedback:\\nIf the input cannot be classified into any of the given categories, classify it as “Others.”\\n\\nInstructions for Output:\\n1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\\n2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\\n\\nOutput Format:\\n\\nReturn your classification in the following JSON format:\\n\\n{\\n  \\\"category\\\": \\\"<Selected Category>\\\",\\n  \\\"specific_tags\\\": [\\\"<Selected Tag 1>\\\", \\\"<Selected Tag 2>\\\", ...]\\n}\\n\\n\\n\\nExample Inputs and Outputs:\\n\\n- Input:\\n\\nLocal sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Weather\\\",\\n  \\\"specific_tags\\\": [\\\"Severe Winds\\\"]\\n}\\n\\n- Input:\\n\\nInformation received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Roadway Closure\\\", \\\"Public Safety Advisory\\\"]\\n}\\n\\n- Input:\\n\\nProtests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Worker Strike\\\",\\n  \\\"specific_tags\\\": [\\\"Protest\\\", \\\"Civil Unrest Advisory\\\"]\\n}\\n\\n- Input:\\n\\nGovernment sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Accident\\\",\\n  \\\"specific_tags\\\": [\\\"Non-industrial Fire\\\"]\\n}\\n\\n- Input:\\n\\nLocal media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Cargo Theft\\\", \\\"Organized Crime\\\"]\\n}\\n\\n- Input:\\n\\nAnonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Cyber Attack\\\",\\n  \\\"specific_tags\\\": [\\\"Ransomware\\\", \\\"Data Breach\\\"]\\n}\\n\\n- Input:\\n\\nThe Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Others\\\",\\n  \\\"specific_tags\\\": [\\\"Outbreak of Disease\\\"]\\n}\\n\\n- Input:\\n\\nAn incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Human Error\\\",\\n  \\\"specific_tags\\\": [\\\"Workplace Accident\\\"]\\n}\\n\\n- Input:\\n\\nShipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Customs Delay\\\", \\\"Port Disruption\\\"]\\n}\\n\\n- Input:\\n\\nRussian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\\n\\n\\nHuman: - Input:\\n\\nCourts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\\n\\n- Output:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1147 [00:03<58:52,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [2.82s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"qwen2.5:3b\",\n",
      "          \"created_at\": \"2024-12-25T20:48:19.3787668Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 774343700,\n",
      "          \"load_duration\": 83902000,\n",
      "          \"prompt_eval_count\": 2081,\n",
      "          \"prompt_eval_duration\": 217000000,\n",
      "          \"eval_count\": 25,\n",
      "          \"eval_duration\": 412000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"qwen2.5:3b\",\n",
      "              \"created_at\": \"2024-12-25T20:48:19.3787668Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 774343700,\n",
      "              \"load_duration\": 83902000,\n",
      "              \"prompt_eval_count\": 2081,\n",
      "              \"prompt_eval_duration\": 217000000,\n",
      "              \"eval_count\": 25,\n",
      "              \"eval_duration\": 412000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-036b0985-0acb-4510-a1b2-fa8cb89b831b-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 2081,\n",
      "              \"output_tokens\": 25,\n",
      "              \"total_tokens\": 2106\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.82s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "Setting debug mode to: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [53:52<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3232.47 seconds\n",
      "qwen2.5:3b/shots-10(2.818) metrics: {'f1': 0.9033106711754157, 'accuracy': 0.8823016564952049}\n",
      "CPU times: total: 5min 8s\n",
      "Wall time: 53min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:3b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f19adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Task: Classify Inputs into Predefined Categories\n",
      "\n",
      "Your primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\n",
      "\n",
      "Guidelines:\n",
      "1. Understand the Categories:\n",
      "Each category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\n",
      "\n",
      "{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\n",
      "\n",
      "2. Contextual Analysis:\n",
      "Consider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\n",
      "3. Handling Ambiguity:\n",
      "For ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\n",
      "4. Ensure Accuracy and Consistency:\n",
      "Strive for consistent and accurate classifications. Avoid arbitrary or random assignments.\n",
      "5. Provide Feedback:\n",
      "If the input cannot be classified into any of the given categories, classify it as “Others.”\n",
      "\n",
      "Instructions for Output:\n",
      "1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\n",
      "2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\n",
      "\n",
      "Output Format:\n",
      "\n",
      "Return your classification in the following JSON format:\n",
      "\n",
      "{\n",
      "  \"category\": \"<Selected Category>\",\n",
      "  \"specific_tags\": [\"<Selected Tag 1>\", \"<Selected Tag 2>\", ...]\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Example Inputs and Outputs:\n",
      "\n",
      "- Input:\n",
      "\n",
      "Local sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Weather\",\n",
      "  \"specific_tags\": [\"Severe Winds\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Information received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Administrative Issue\",\n",
      "  \"specific_tags\": [\"Roadway Closure\", \"Public Safety Advisory\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Protests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Worker Strike\",\n",
      "  \"specific_tags\": [\"Protest\", \"Civil Unrest Advisory\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Government sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Accident\",\n",
      "  \"specific_tags\": [\"Non-industrial Fire\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Local media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Terrorism\",\n",
      "  \"specific_tags\": [\"Cargo Theft\", \"Organized Crime\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Anonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Cyber Attack\",\n",
      "  \"specific_tags\": [\"Ransomware\", \"Data Breach\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "The Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Others\",\n",
      "  \"specific_tags\": [\"Outbreak of Disease\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "An incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Human Error\",\n",
      "  \"specific_tags\": [\"Workplace Accident\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Shipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Administrative Issue\",\n",
      "  \"specific_tags\": [\"Customs Delay\", \"Port Disruption\"]\n",
      "}\n",
      "\n",
      "- Input:\n",
      "\n",
      "Russian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\n",
      "\n",
      "- Output:\n",
      "\n",
      "{\n",
      "  \"category\": \"Terrorism\",\n",
      "  \"specific_tags\": [\"Bomb Threat\", \"Public Safety\"]\n",
      "}\n",
      "\n",
      "\n",
      "Human: - Input:\n",
      "\n",
      "Courts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\n",
      "\n",
      "- Output:\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"System: Task: Classify Inputs into Predefined Categories\\n\\nYour primary objective is to analyze the given input and assign it to one of the predefined categories: ['Weather', 'Worker Strike', 'Administrative Issue', 'Human Error', 'Cyber Attack', 'Terrorism', 'Accident', 'Others']. Evaluate the content carefully and use the defining characteristics of each category to ensure an accurate classification.\\n\\nGuidelines:\\n1. Understand the Categories:\\nEach category has specific attributes that distinguish it. Familiarize yourself with these attributes by referring to the category descriptions provided in the JSON below. Use these details to guide your classification:\\n\\n{'Weather': ['Flooding', 'Severe Winds', 'Weather Advisory', 'Tropical Cyclone', 'Storm', 'Ice Storm', 'Earthquake', 'Tornado', 'Typhoon', 'Landslide', 'Water', 'Hurricane', 'Wildfire', 'Blizzard', 'Hail'], 'Worker Strike': ['Mine Workers Strike', 'Production Halt', 'Protest', 'Riot', 'Port Strike', 'General Strike', 'Civil Service Strike', 'Civil Unrest Advisory', 'Cargo Transportation Strike', 'Energy Sector Strike'], 'Administrative Issue': ['Port Congestion', 'Police Operations', 'Roadway Closure', 'Disruption', 'Cargo', 'Industrial Action', 'Port Disruption', 'Cargo Disruption', 'Power Outage', 'Port Closure', 'Maritime Advisory', 'Train Delays', 'Ground Transportation Advisory', 'Public Transportation Disruption', 'Trade Regulation', 'Customs Regulation', 'Regulatory Advisory', 'Industry Directives', 'Security Advisory', 'Public Holidays', 'Customs Delay', 'Public Health Advisory', 'Detention', 'Aviation Advisory', 'Waterway Closure', 'Plant Closure', 'Border Closure', 'Delay', 'Industrial zone shutdown', 'Trade Restrictions', 'Closure', 'Truck Driving Ban', 'Insolvency', 'Environmental Regulations', 'Postal Disruption', 'Travel Warning'], 'Human Error': ['Workplace Accident', 'Individuals in Focus', 'Military Operations', 'Flight Delays', 'Cancellations', 'Political Info', 'Political Event'], 'Cyber Attack': ['Network Disruption', 'Ransomware', 'Data breach', 'Phishing'], 'Terrorism': ['Bombing', 'Warehouse Theft', 'Public Safety', 'Security', 'Organized Crime', 'Piracy', 'Kidnap', 'Shooting', 'Robbery', 'Cargo theft', 'Bomb Detonation', 'Terror Attack', 'Outbreak Of War', 'Militant Action'], 'Accident': ['Hazmat Response', 'Maritime Accident', 'Vehicle Accident', 'Death', 'Injury', 'Non-industrial Fire', 'Chemical Spill', 'Industrial Fire', 'Fuel Disruption', 'Airline Incident', 'Crash', 'Explosion', 'Train Accident', 'Derailment', 'Sewage Disruption', 'Barge Accident', 'Bridge Collapse', 'Structure Collapse', 'Airport Accident', 'Force Majeure', 'Telecom Outage'], 'Others': ['Miscellaneous Events', 'Miscellaneous Strikes', 'Outbreak of disease']}\\n\\n2. Contextual Analysis:\\nConsider the broader context of the input. If an input could potentially fit into multiple categories, select the one that most closely aligns with its primary intent or focus.\\n3. Handling Ambiguity:\\nFor ambiguous inputs or those that do not clearly align with any category, choose the category that most closely matches the content provided.\\n4. Ensure Accuracy and Consistency:\\nStrive for consistent and accurate classifications. Avoid arbitrary or random assignments.\\n5. Provide Feedback:\\nIf the input cannot be classified into any of the given categories, classify it as “Others.”\\n\\nInstructions for Output:\\n1. Once the category is identified, provide “specific tags” by selecting from the list corresponding to the identified category, as defined in the JSON.\\n2. Ensure the selected “specific tags” accurately reflect the details and context of the input.\\n\\nOutput Format:\\n\\nReturn your classification in the following JSON format:\\n\\n{\\n  \\\"category\\\": \\\"<Selected Category>\\\",\\n  \\\"specific_tags\\\": [\\\"<Selected Tag 1>\\\", \\\"<Selected Tag 2>\\\", ...]\\n}\\n\\n\\n\\nExample Inputs and Outputs:\\n\\n- Input:\\n\\nLocal sources reported that operations at Pier 1 and 2 container terminals at the Port of Durban have suspended due to strong winds on December 27 from 18:50 (local time) and resumed at 23:10 on the same day. For Pier 2 terminal, operations stopped at 19:30 and resumed at 20:35 respectively.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Weather\\\",\\n  \\\"specific_tags\\\": [\\\"Severe Winds\\\"]\\n}\\n\\n- Input:\\n\\nInformation received states that emergency personnel are working to contain a blaze at Off Road Warehouse in commercial San Diego, on 17 November. It is detailed that the store is located at 7915 Balboa Avenue. Traffic maps show that Balboa Avenue is closed both ways between Mercury Street and Convoy Street. Travelers should use caution in the area and divert away from any encountered fire suppression operations.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Roadway Closure\\\", \\\"Public Safety Advisory\\\"]\\n}\\n\\n- Input:\\n\\nProtests against climate change are anticipated nationwide on 29 November and 6 December as part of the ‘Fridays for Future’ global climate strike. Specific details of planned events have not been confirmed, but are likely to occur in major cities across the country. Previous climate strikes have seen large turnout in cities such as New York City, Philadelphia, and Washington, D.C.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Worker Strike\\\",\\n  \\\"specific_tags\\\": [\\\"Protest\\\", \\\"Civil Unrest Advisory\\\"]\\n}\\n\\n- Input:\\n\\nGovernment sources reported a fire at the Woolwich Dockyard, located near Belson Rd and Borgard Rd. No injuries were immediately reported. All rail lines from London towards Slade Green are running again. This incident is closed.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Accident\\\",\\n  \\\"specific_tags\\\": [\\\"Non-industrial Fire\\\"]\\n}\\n\\n- Input:\\n\\nLocal media sources indicated on November 30 that the Ekurhuleni Central Crime Intelligence Unit arrested 4 suspects and recovered computer printer equipment cargo from their November 21 truck theft at the corner of Main Reef Road and Ulysses Street in Cleveland. The truck was en route from Durban to Johannesburg when it was hijacked in Randfontein. The cargo was worth ZAR 5 million (EUR 309018.21; USD 352673.95), and some laptops are still missing. Distributors should be mindful of cargo theft risks in Randfontein and should plan accordingly.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Cargo Theft\\\", \\\"Organized Crime\\\"]\\n}\\n\\n- Input:\\n\\nAnonymous sources have reported that a ransomware attack has disrupted network operations for a major logistics provider. The attack occurred on November 15, and data breaches were confirmed, exposing sensitive customer and shipment details. The company has stated that recovery is underway but advised customers to expect delays.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Cyber Attack\\\",\\n  \\\"specific_tags\\\": [\\\"Ransomware\\\", \\\"Data Breach\\\"]\\n}\\n\\n- Input:\\n\\nThe Selangor Health Department reported that two students of a Secondary School in Pandamaran Jaya in Port Klang had been infected with COVID-19 virus.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Others\\\",\\n  \\\"specific_tags\\\": [\\\"Outbreak of Disease\\\"]\\n}\\n\\n- Input:\\n\\nAn incident of workplace negligence was reported at a construction site in downtown Chicago on November 19, where an unfastened scaffolding collapsed, injuring two workers. Investigations are ongoing to determine accountability.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Human Error\\\",\\n  \\\"specific_tags\\\": [\\\"Workplace Accident\\\"]\\n}\\n\\n- Input:\\n\\nShipping delays were reported at the Port of Los Angeles on December 1 due to a customs system outage. Containers requiring clearance were delayed for up to 12 hours, affecting supply chains across the region.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Administrative Issue\\\",\\n  \\\"specific_tags\\\": [\\\"Customs Delay\\\", \\\"Port Disruption\\\"]\\n}\\n\\n- Input:\\n\\nRussian media sources are reporting that courts, schools, and hospitals across Saint Petersburg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky, and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalize.\\n\\n- Output:\\n\\n{\\n  \\\"category\\\": \\\"Terrorism\\\",\\n  \\\"specific_tags\\\": [\\\"Bomb Threat\\\", \\\"Public Safety\\\"]\\n}\\n\\n\\nHuman: - Input:\\n\\nCourts, schools and hospitals evacuated across Saint Petersberg due to anonymous threats Russian media sources are reporting that courts, schools, and hospitals across Saint Petersberg have been evacuated today due to anonymous threats. It is understood that people have been evacuated from Petrodvorets, Oktyabrsky, Kolpinsky, Petrogradsky, Kuibyshevsky and Sestroretsky district courts. Furthermore, the State University of the Sea and River Fleet, St. Petersburg State University of Railway Engineering, Higher School of Folk Arts, St. Petersburg State University of Telecommunications, and S.M. Military Medical Academy Kirov have all been evacuated. This is the fourth consecutive week of evacuations from public buildings due to such threats. It is not known when the situation will normalise.\\n\\n- Output:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdefff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:7b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:45<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3405.89 seconds\n",
      "qwen2.5:7b/shots-00(2.969) metrics: {'f1': 0.8984232340546373, 'accuracy': 0.8945074106364429}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [55:48<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3348.79 seconds\n",
      "qwen2.5:7b/shots-01(2.920) metrics: {'f1': 0.9151196316717413, 'accuracy': 0.9006102877070619}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:25<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3385.76 seconds\n",
      "qwen2.5:7b/shots-02(2.952) metrics: {'f1': 0.9218899578107954, 'accuracy': 0.916303400174368}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [56:41<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3401.36 seconds\n",
      "qwen2.5:7b/shots-04(2.965) metrics: {'f1': 0.9171679063397298, 'accuracy': 0.9102005231037489}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [57:06<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3426.60 seconds\n",
      "qwen2.5:7b/shots-08(2.987) metrics: {'f1': 0.9128203521592847, 'accuracy': 0.9032258064516129}\n",
      "CPU times: total: 25min 54s\n",
      "Wall time: 4h 42min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:7b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2baa616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:7b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [57:01<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3421.56 seconds\n",
      "qwen2.5:7b/shots-10(2.983) metrics: {'f1': 0.9245568445058716, 'accuracy': 0.9180470793374019}\n",
      "CPU times: total: 5min 9s\n",
      "Wall time: 57min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:7b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "677651da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:14b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:03:05<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 3785.07 seconds\n",
      "qwen2.5:14b/shots-00(3.300) metrics: {'f1': 0.89046817042476, 'accuracy': 0.8884045335658239}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:17<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 3737.96 seconds\n",
      "qwen2.5:14b/shots-01(3.259) metrics: {'f1': 0.9443315044460271, 'accuracy': 0.939843068875327}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:33<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 3753.04 seconds\n",
      "qwen2.5:14b/shots-02(3.272) metrics: {'f1': 0.9423757560904567, 'accuracy': 0.939843068875327}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:23<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 3743.46 seconds\n",
      "qwen2.5:14b/shots-04(3.264) metrics: {'f1': 0.9303027020650105, 'accuracy': 0.925893635571055}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:43<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 3763.36 seconds\n",
      "qwen2.5:14b/shots-08(3.281) metrics: {'f1': 0.9394999774603564, 'accuracy': 0.937227550130776}\n",
      "CPU times: total: 26min 4s\n",
      "Wall time: 5h 13min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:14b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c145398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:14b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [1:02:56<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 3776.10 seconds\n",
      "qwen2.5:14b/shots-10(3.292) metrics: {'f1': 0.9508787846809517, 'accuracy': 0.9476896251089799}\n",
      "CPU times: total: 5min 14s\n",
      "Wall time: 1h 2min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:14b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47302897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:32b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 0\n",
      "Generating prompt templates for 0 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:30:33<00:00,  7.88s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 0: 9033.78 seconds\n",
      "qwen2.5:32b/shots-00(7.876) metrics: {'f1': 0.9278176000438443, 'accuracy': 0.925893635571055}\n",
      "* Evaluating with num_shots: 1\n",
      "Generating prompt templates for 1 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:21:37<00:00,  7.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 1: 8497.30 seconds\n",
      "qwen2.5:32b/shots-01(7.408) metrics: {'f1': 0.9563898297915706, 'accuracy': 0.953792502179599}\n",
      "* Evaluating with num_shots: 2\n",
      "Generating prompt templates for 2 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:31:23<00:00,  7.92s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 2: 9083.60 seconds\n",
      "qwen2.5:32b/shots-02(7.919) metrics: {'f1': 0.9583493794277075, 'accuracy': 0.9572798605056669}\n",
      "* Evaluating with num_shots: 4\n",
      "Generating prompt templates for 4 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:30:36<00:00,  7.88s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 4: 9036.51 seconds\n",
      "qwen2.5:32b/shots-04(7.878) metrics: {'f1': 0.9613234626565559, 'accuracy': 0.959895379250218}\n",
      "* Evaluating with num_shots: 8\n",
      "Generating prompt templates for 8 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:35:25<00:00,  8.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 8: 9325.62 seconds\n",
      "qwen2.5:32b/shots-08(8.130) metrics: {'f1': 0.9660024131895552, 'accuracy': 0.96512641673932}\n",
      "CPU times: total: 26min 51s\n",
      "Wall time: 12h 29min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:32b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[0, 1, 2, 4, 8],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa153c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: qwen2.5:32b\n",
      "loading train/test data files\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 4594\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'Headline', 'Details', 'Severity', 'Region', 'Datetime', 'lat', 'lon', 'maritime_label', 'found_ports', 'contains_port_info', 'if_labeled', 'Headline_Details', 'Year', 'Month', 'Week', 'Details_cleaned', 'Category', 'Summarized_label', 'gpt-4o_label'],\n",
      "        num_rows: 1147\n",
      "    })\n",
      "})\n",
      "* Evaluating with num_shots: 10\n",
      "Generating prompt templates for 10 shots with Headline_Details and gpt-4o_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [2:39:36<00:00,  8.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Execution time for num_shots 10: 9576.34 seconds\n",
      "qwen2.5:32b/shots-10(8.349) metrics: {'f1': 0.9644688258204385, 'accuracy': 0.962510897994769}\n",
      "CPU times: total: 5min 18s\n",
      "Wall time: 2h 39min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llm_toolkit.eval_openai import *\n",
    "\n",
    "evaluate_model_with_num_shots(\n",
    "    \"qwen2.5:32b\",\n",
    "    data_path,\n",
    "    results_path=results_path,\n",
    "    ollama=True,\n",
    "    range_num_shots=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc24fc",
   "metadata": {},
   "source": [
    "## System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3727bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cbce17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 63.70 GB\n",
      "Available memory: 38.69 GB\n",
      "Used memory: 25.00 GB\n",
      "Memory percentage: 39.3%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the system memory information\n",
    "memory_info = psutil.virtual_memory()\n",
    "\n",
    "# Print the total, available, and used memory\n",
    "print(f\"Total memory: {memory_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available memory: {memory_info.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used memory: {memory_info.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Memory percentage: {memory_info.percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ef7ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Windows\n",
      "Node Name: Donghao-m18\n",
      "Release: 10\n",
      "Version: 10.0.26100\n",
      "Machine: AMD64\n",
      "Processor: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "\n",
    "def get_os_info():\n",
    "    os_info = {\n",
    "        \"System\": platform.system(),\n",
    "        \"Node Name\": platform.node(),\n",
    "        \"Release\": platform.release(),\n",
    "        \"Version\": platform.version(),\n",
    "        \"Machine\": platform.machine(),\n",
    "        \"Processor\": platform.processor(),\n",
    "    }\n",
    "    return os_info\n",
    "\n",
    "\n",
    "os_info = get_os_info()\n",
    "for key, value in os_info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e6d9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date/time: 2024-12-27 08:47:28.388740\n"
     ]
    }
   ],
   "source": [
    "# printe current date & time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print(\"Current date/time:\", now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maritime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
